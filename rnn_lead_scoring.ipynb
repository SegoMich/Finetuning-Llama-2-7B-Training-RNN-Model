{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7M6xpj5QhmaA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# Load lead data\n",
    "leads_df = pd.read_csv('lead.csv')\n",
    "\n",
    "# Preprocess industry and lead status\n",
    "label_encoder_industry = LabelEncoder()\n",
    "leads_df['industry_encoded'] = label_encoder_industry.fit_transform(leads_df['industry'])\n",
    "\n",
    "label_encoder_status = LabelEncoder()\n",
    "leads_df['lead_status_encoded'] = label_encoder_status.fit_transform(leads_df['lead_status'])\n",
    "\n",
    "# Features\n",
    "X = leads_df[['industry_encoded', 'lead_status_encoded']].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "r9WQRa7th368"
   },
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e1ZN4sGmh6js"
   },
   "outputs": [],
   "source": [
    "# Perform KMeans clustering\n",
    "k = 5  # Assuming 5 clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "leads_df['lead_cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Scale the cluster assignments to the range [0, 10]\n",
    "scaler_cluster = MinMaxScaler(feature_range=(0, 10))\n",
    "leads_df['lead_score'] = scaler_cluster.fit_transform(leads_df['lead_cluster'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XQmPIn7lh8_X"
   },
   "outputs": [],
   "source": [
    "# Features and target variable for the RNN model\n",
    "X_rnn = leads_df[['industry_encoded', 'lead_status_encoded']].values\n",
    "y_rnn = leads_df['lead_score'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize features for the RNN model\n",
    "scaler_rnn = StandardScaler()\n",
    "X_scaled_rnn = scaler_rnn.fit_transform(X_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "82ynULasiFFb"
   },
   "outputs": [],
   "source": [
    "# Reshape input data for the RNN model\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_scaled_rnn, y_rnn, test_size=0.2, random_state=42)\n",
    "X_train_rnn = X_train_rnn.reshape(X_train_rnn.shape[0], 1, X_train_rnn.shape[1])\n",
    "X_test_rnn = X_test_rnn.reshape(X_test_rnn.shape[0], 1, X_test_rnn.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eWJW_KEKiKKA"
   },
   "outputs": [],
   "source": [
    "# Define RNN model\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(GRU(units=64, dropout=0.2, recurrent_dropout=0.2, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])))\n",
    "model_rnn.add(Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OqfcQXUQiUdi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 - 9s - loss: 28.3180 - mae: 4.0902 - val_loss: 36.0473 - val_mae: 4.8827 - 9s/epoch - 3s/step\n",
      "Epoch 2/20\n",
      "3/3 - 0s - loss: 28.0549 - mae: 4.0750 - val_loss: 35.6989 - val_mae: 4.8607 - 172ms/epoch - 57ms/step\n",
      "Epoch 3/20\n",
      "3/3 - 0s - loss: 27.7806 - mae: 4.0595 - val_loss: 35.3477 - val_mae: 4.8384 - 140ms/epoch - 47ms/step\n",
      "Epoch 4/20\n",
      "3/3 - 0s - loss: 27.5025 - mae: 4.0429 - val_loss: 34.9961 - val_mae: 4.8159 - 125ms/epoch - 42ms/step\n",
      "Epoch 5/20\n",
      "3/3 - 0s - loss: 27.2062 - mae: 4.0262 - val_loss: 34.6663 - val_mae: 4.7941 - 164ms/epoch - 55ms/step\n",
      "Epoch 6/20\n",
      "3/3 - 0s - loss: 26.9875 - mae: 4.0094 - val_loss: 34.3403 - val_mae: 4.7722 - 130ms/epoch - 43ms/step\n",
      "Epoch 7/20\n",
      "3/3 - 0s - loss: 26.6803 - mae: 3.9935 - val_loss: 34.0129 - val_mae: 4.7500 - 125ms/epoch - 42ms/step\n",
      "Epoch 8/20\n",
      "3/3 - 0s - loss: 26.4854 - mae: 3.9833 - val_loss: 33.6727 - val_mae: 4.7268 - 170ms/epoch - 57ms/step\n",
      "Epoch 9/20\n",
      "3/3 - 0s - loss: 26.1920 - mae: 3.9684 - val_loss: 33.3340 - val_mae: 4.7034 - 120ms/epoch - 40ms/step\n",
      "Epoch 10/20\n",
      "3/3 - 0s - loss: 26.2218 - mae: 3.9692 - val_loss: 32.9793 - val_mae: 4.6790 - 120ms/epoch - 40ms/step\n",
      "Epoch 11/20\n",
      "3/3 - 0s - loss: 25.8125 - mae: 3.9475 - val_loss: 32.6381 - val_mae: 4.6549 - 125ms/epoch - 42ms/step\n",
      "Epoch 12/20\n",
      "3/3 - 0s - loss: 25.2500 - mae: 3.9147 - val_loss: 32.2596 - val_mae: 4.6285 - 90ms/epoch - 30ms/step\n",
      "Epoch 13/20\n",
      "3/3 - 0s - loss: 25.0249 - mae: 3.9063 - val_loss: 31.8730 - val_mae: 4.6011 - 83ms/epoch - 28ms/step\n",
      "Epoch 14/20\n",
      "3/3 - 0s - loss: 24.8750 - mae: 3.8909 - val_loss: 31.4666 - val_mae: 4.5724 - 90ms/epoch - 30ms/step\n",
      "Epoch 15/20\n",
      "3/3 - 0s - loss: 24.3645 - mae: 3.8606 - val_loss: 31.0741 - val_mae: 4.5437 - 85ms/epoch - 28ms/step\n",
      "Epoch 16/20\n",
      "3/3 - 0s - loss: 24.3137 - mae: 3.8613 - val_loss: 30.6870 - val_mae: 4.5146 - 87ms/epoch - 29ms/step\n",
      "Epoch 17/20\n",
      "3/3 - 0s - loss: 23.9614 - mae: 3.8395 - val_loss: 30.2694 - val_mae: 4.4838 - 89ms/epoch - 30ms/step\n",
      "Epoch 18/20\n",
      "3/3 - 0s - loss: 23.3538 - mae: 3.7918 - val_loss: 29.8255 - val_mae: 4.4507 - 85ms/epoch - 28ms/step\n",
      "Epoch 19/20\n",
      "3/3 - 0s - loss: 23.1984 - mae: 3.7980 - val_loss: 29.3757 - val_mae: 4.4163 - 95ms/epoch - 32ms/step\n",
      "Epoch 20/20\n",
      "3/3 - 0s - loss: 22.8261 - mae: 3.7770 - val_loss: 28.9123 - val_mae: 4.3808 - 90ms/epoch - 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e3e7e2f9d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model_rnn.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train model\n",
    "model_rnn.fit(X_train_rnn, y_train_rnn, epochs=20, batch_size=32, validation_data=(X_test_rnn, y_test_rnn), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BVLeUexciVYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 775ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict lead scores\n",
    "y_pred_rnn = model_rnn.predict(X_test_rnn)\n",
    "\n",
    "# Scale predicted lead scores to the range [0, 10]\n",
    "scaler_lead_score = MinMaxScaler(feature_range=(0, 10))\n",
    "y_pred_scaled = scaler_lead_score.fit_transform(y_pred_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 28.912290573120117\n",
      "Mean Absolute Error: 4.380837440490723\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Predicted lead score for the new lead: 8.024524688720703\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "mse, mae = model_rnn.evaluate(X_test_rnn, y_test_rnn, verbose=0)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Example prediction for a new lead\n",
    "new_lead_features = [[label_encoder_industry.transform(['Technology'])[0], \n",
    "                      label_encoder_status.transform(['open'])[0]]]\n",
    "new_lead_features_scaled = scaler_rnn.transform(new_lead_features)\n",
    "new_lead_features_scaled_reshaped = new_lead_features_scaled.reshape(1, 1, 2)\n",
    "predicted_lead_score = model_rnn.predict(new_lead_features_scaled_reshaped)\n",
    "predicted_lead_score_scaled = scaler_lead_score.transform(predicted_lead_score)[0][0]\n",
    "\n",
    "print(f\"Predicted lead score for the new lead: {predicted_lead_score_scaled}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
